{"componentChunkName":"component---node-modules-gatsby-theme-buzzing-src-gatsby-theme-blog-core-templates-post-query-js","path":"/en/reddit/r/investing/comments/nzv40f/tracking_the_value_of_3_reddit_scrapers_for_30/","result":{"data":{"site":{"siteMetadata":{"title":"国外股市热门","author":"Buzzing.cc","description":"用中文浏览国外股票社区里的热门讨论","keywords":["buzzing","美股","股票","股市"],"siteUrl":"https://stocks.buzzing.cc","telegram":"@stocks_top","iconUrl":"https://stocks.buzzing.cc/avatar.png","defaultSocialImageUrl":null,"social":[{"name":"Reddit Stocks","url":"https://www.reddit.com/r/stocks","external":true},{"name":"Reddit Investing","url":"https://www.reddit.com/r/investing","external":true},{"name":"Charlie Bilello's twitter","url":"https://twitter.com/charliebilello","external":true},{"name":"Buzzing","url":"https://www.buzzing.cc/","external":true}],"menuLinks":[{"name":"每周精选","url":"/issues","external":null}],"disqus":null,"utterances":null,"localize":[{"title":"Buzzing on Stocks","description":"See popular discussions in foreign stock communities in your native language","keywords":["buzzing","stocks","U.S. stocks"],"locale":"en","social":{"name":null,"url":null,"external":null},"menuLinks":[{"name":"Weekly Selection","url":"/en/issues","external":null}]},{"title":"國外股市熱門","description":"用中文瀏覽國外股票社區裡的熱門討論","keywords":["buzzing","美股","股票","股市"],"locale":"zh-Hant","social":null,"menuLinks":[{"name":"每週精選","url":"/zh-Hant/issues","external":null}]},{"title":"米国株式市場人気の話し合います","description":"人気の米国株式市場の話し合いまを日本語で閲覧","keywords":["buzzing","米国株式市場"],"locale":"ja","social":null,"menuLinks":[]}]}},"blogPost":{"id":"RedditPost-e228c254-01f9-5803-ac8e-ba555f8e0130","excerpt":"Just like everyone else I want to find a way to use these Reddit scrapers to\nactually make some money. Since I'm a data nerd I track any that I can and\nanalyze their hit rate, profitability, etc. I was using Unbias very successfully\nand making good money until it stopped updating (see original post…","body":"<!-- SC_OFF --><div class=\"md\"><p>Just like everyone else I want to find a way to use these Reddit scrapers to actually make some money. Since I&#39;m a data nerd I track any that I can and analyze their hit rate, profitability, etc. I was using Unbias very successfully and making good money until it stopped updating (<a href=\"https://www.reddit.com/r/stocks/comments/m71xi8/a_month_of_tracking_stock_scrapers_for/\">see original post here</a>)</p>\n\n<p>&#x200B;</p>\n\n<p>Since then I have been tracking 3 scrapers and 1 methodology I saw here:</p>\n\n<ul>\n<li><a href=\"https://www.reddit.com/r/MillennialBets/wiki/index/user/theindulgery\">Millenial Bets</a></li>\n<li><a href=\"https://hype-rider.com/reddit\">Hype Rider</a></li>\n<li><a href=\"https://dayminer.herokuapp.com/\">Dayminer</a></li>\n<li><a href=\"https://docs.google.com/spreadsheets/d/1wBbawSwzpei5Q93Erg26Ii8JADFryoM2smpNTx5F9aM/edit#gid=910606400\">Using Finviz to see if buying the biggest losers of the day and selling the next morning for a 1% profit would work</a></li>\n</ul>\n\n<p>&#x200B;</p>\n\n<p><strong>Fair warning:</strong> Google Sheets struggles with large amounts of data and a lot of people logging in, so I created multiples of each spreadsheet. If you have trouble getting in all I can recommend is continuing to try. If you do, make a copy for yourself.</p>\n\n<p>&#x200B;</p>\n\n<p><strong>Summaries:</strong></p>\n\n<ul>\n<li><strong>Easiest to gather data: Millenial Bets</strong>. This is a straight copy/paste. The others required a lot of Excel copy, pasting, sorting, etc to get it to fit into the sheets</li>\n<li><strong>Best average returns: Millenial Bets.</strong> This may be because they had the biggest quantity of results. It&#39;s hard to narrow this down to just a few tickers to buy, so looks good as a paper trader but hard to put into use in the real world</li>\n<li><strong>Best at returning a small list of tickers to buy: Dayminer.</strong> This data narrows down to just a few, or sometimes none, per day. But the ones that do hit tend to hit pretty consistently</li>\n</ul>\n\n<p>&#x200B;</p>\n\n<p><strong>End Results from tracking the data:</strong> <em>(When paper trading I chose categories that had a % of Profitable vs Non-Profitable returns of greater than 90%. I was aiming for highest success rate of being profitable)</em></p>\n\n<ul>\n<li><p><strong>Millenial Bets:</strong> </p>\n\n<ul>\n<li><strong>Total data points:</strong> 5573</li>\n<li><strong>Number of paper trades:</strong> 2212</li>\n<li><strong>% return (avg):</strong> 11.44%</li>\n<li><strong>% return (max):</strong> 50%</li>\n<li><strong># of days to max profit (avg):</strong> 6<br/></li>\n</ul></li>\n<li><p><strong>Hype Rider:</strong> </p>\n\n<ul>\n<li><strong>Total data points:</strong> 5425</li>\n<li><strong>Number of paper trades:</strong> 714</li>\n<li><strong>% return (avg):</strong> 7.03%</li>\n<li><strong>% return (max): 13.19</strong>%</li>\n<li><strong># of days to max profit (avg):</strong> 4<br/></li>\n</ul></li>\n<li><p><strong>Dayminer:</strong> </p>\n\n<ul>\n<li><strong>Total data points:</strong> 5111</li>\n<li><strong>Number of paper trades:</strong> 278</li>\n<li><strong>% return (avg):</strong> 8.67%</li>\n<li><strong>% return (max):</strong> 29.77%</li>\n<li><strong># of days to max profit (avg):</strong> 5</li>\n</ul></li>\n</ul>\n\n<p>&#x200B;</p>\n\n<p><strong>How do I use this data?</strong> This is the question I get asked the most often. Here&#39;s what I do:</p>\n\n<ol>\n<li>Every morning before market open I copy the data from the scrapers, do whatever post-processing I need to do to get it to fit into the sheets, then paste into the sheets. This captures all the sentiment data from the last 24 hours</li>\n<li>When I&#39;m ready to buy something I look at the highest profitability categories in the data crunching tabs</li>\n<li>From there I narrow down THAT DAY&#39;S list of tickers based on the highest profitability categories</li>\n<li>I&#39;ll do a quick search on Reddit to see if overall sentiment is bullish or bearish. If everyone looks hopeful I&#39;ll buy</li>\n<li>I look at the average % returns and the average number of days to get there and those are my exit points<br/></li>\n</ol>\n\n<p>&#x200B;</p>\n\n<p>Now, on to the good stuff. Here are the links:<br/>\n<strong>Millenial Bets:</strong> <a href=\"https://imgur.com/gallery/nn14i7y\">Screen shots of the tables</a> | <a href=\"https://docs.google.com/spreadsheets/d/1iWKdaMUSdQ5G5ZUHabL7z5YKR-ZZalLqCD1Yv8ougZI/edit?usp=sharing\">Data (1)</a> | <a href=\"https://docs.google.com/spreadsheets/d/1wav7ZnQlk6NE1vMWFmx941fHzVMi_QFKlbtRRKsEaCY/edit?usp=sharing\">Data (2)</a> | <a href=\"https://docs.google.com/spreadsheets/d/1PXKCzJbva1NMAajASGNpmeO6LBVUT2PjZME3sS8S7yU/edit?usp=sharing\">Data (3)</a></p>\n\n<p><strong>Hype Rider:</strong> <a href=\"https://imgur.com/gallery/swbVZji\">Screen shots of the tables</a> | <a href=\"https://docs.google.com/spreadsheets/d/1vLUQTkZPzF924btqTWJXVrgmkLLHK4oOf1F1d3cSGP4/edit?usp=sharing\">Data (1)</a> | <a href=\"https://docs.google.com/spreadsheets/d/1GZUl3PeGSHMg8Hld4-9Z5COHWf_sjbI7q3AnwMZvwV4/edit?usp=sharing\">Data (2)</a> | <a href=\"https://docs.google.com/spreadsheets/d/1u5_nv1PxAdCvBN-m3gPODICrQA32UVz_FLEpskLm0Dw/edit?usp=sharing\">Data (3)</a></p>\n\n<p><strong>Dayminer</strong>: <a href=\"https://imgur.com/gallery/xUwlPTu\">Screen shots of tables</a> | <a href=\"https://docs.google.com/spreadsheets/d/1rRMFuvhHfC1SwZzZa1Y0AevB7U3dGmOECoKjUN9So8o/edit?usp=sharing\">Data (1)</a> | <a href=\"https://docs.google.com/spreadsheets/d/11-c3JLGOlpNx1A4Of_AE5Xq3nmoUSRJVCM-FmhXiSes/edit?usp=sharing\">Data (2)</a> | <a href=\"https://docs.google.com/spreadsheets/d/1ojmjOf0Xxzy0nppxCAhplw104f0btOzfGhbAHg5RRE4/edit?usp=sharing\">Data (3)</a></p>\n\n<p><strong>Finviz All Time Low data:</strong> <a href=\"https://imgur.com/gallery/UHnUUAU\">Screen shots of the tables</a> | <a href=\"https://docs.google.com/spreadsheets/d/1kQMqf6gMeRfaJgYUDPB2Mux7nXJX8KsH-J3bJaYF-Jw/edit?usp=sharing\">Data (1)</a>| <a href=\"https://docs.google.com/spreadsheets/d/1JnvE1ud8sdGstD28P8Y940icrajiifhOdxL0LyNVCQQ/edit?usp=sharing\">Data (2)</a> | <a href=\"https://docs.google.com/spreadsheets/d/1EdBUMWr36t0Ibq-Yjn-1OnXjLyeJ7-Tw6q0q_h043do/edit?usp=sharing\">Data (3)</a> (Nothing really clear came of this data so I didn&#39;t highlight it in the post)</p>\n</div><!-- SC_ON -->","slug":"/reddit/r/investing/comments/nzv40f/tracking_the_value_of_3_reddit_scrapers_for_30/","title":"Tracking the value of 3 Reddit scrapers for 30 days","tags":["investing","reddit"],"date":"June 15, 2021","dateISO":"2021-06-15T01:18:55.000Z","datetime":"2021-06-15 01:18","image":null,"imageAlt":null,"socialImage":null,"__typename":"SocialMediaPost","thirdPartyId":"e228c254-01f9-5803-ac8e-ba555f8e0130","provider":"Reddit","url":"https://www.reddit.com/r/investing/comments/nzv40f/tracking_the_value_of_3_reddit_scrapers_for_30/","originalUrl":"https://www.reddit.com/r/investing/comments/nzv40f/tracking_the_value_of_3_reddit_scrapers_for_30/","imageRemote":null,"video":null,"channel":"investing","channelUrl":"https://www.reddit.com/r/investing","author":"TheIndulgery","authorUrl":"https://www.reddit.com/user/TheIndulgery","authorImage":null,"authorImageRemote":null,"authorSlug":"TheIndulgery","score":121,"views":null,"sharedCount":null,"likeCount":null,"sharedContent":null,"parent":{"localize":[{"title":"3つのRedditスクレイパーの値を30日間追跡する","the_new_excerpt":"他の人と同じように、私もこのRedditスクレイパーを使って実際にお金を稼ぐ方法を見つけたいと思っています。\n実際にお金を稼ぐ方法を探しています。私はデータオタクなので、できる限りトラッキングして\nヒット率や収益性などを分析しています。私はUnbiasを非常にうまく使っていました。\n順調に稼いでいたのですが、更新が止まってしまいました（元記事参照）。","locale":"ja"},{"title":"追踪3个Reddit搜刮器的价值，为期30天","the_new_excerpt":"就像其他人一样，我想找到一种方法，利用这些Reddit刮刀来\n真正赚到一些钱。因为我是一个数据呆子，所以我追踪任何我可以追踪的东西，并\n分析他们的点击率、盈利能力等。我曾非常成功地使用Unbias\n赚了不少钱，直到它停止更新（见原帖...","locale":"zh"},{"title":"追蹤3個Reddit搜刮器的價值，爲期30天","the_new_excerpt":"就像其他人一樣，我想找到一種方法，利用這些Reddit刮刀來\n真正賺到一些錢。因爲我是一個數據呆子，所以我追蹤任何我可以追蹤的東西，並\n分析他們的點擊率、盈利能力等。我曾非常成功地使用Unbias\n賺了不少錢，直到它停止更新（見原帖...","locale":"zh-Hant"}]}},"previous":{"id":"RedditPost-8b349480-b58c-5e00-9146-2f700fbd375c","excerpt":"Hi!\n\nI have recently been the recipient of a $10M+ windfall. Eventually, my plan is\nto deploy a simple 3-fund strategy (probably using DCA), rebalanced ~yearly, and\nlive off the returns (I am in my early 40s).\n\nI am very analytical, and have previously managed large-ish amounts of…","slug":"/reddit/r/Bogleheads/comments/nzxxqm/windfall_and_practical_aspects_of_3fund_deployment/","title":"Windfall and practical aspects of 3-fund deployment","date":"June 15, 2021","__typename":"SocialMediaPost","parent":{"localize":[{"title":"3ファンド展開の風穴と実務面","the_new_excerpt":"こんにちは。\n\n私は最近、1000万円以上の大金を手にしました。最終的に私が考えているのは\nシンプルな3つのファンド戦略（おそらくDCAを使用）を展開し、年に1回リバランスして\nそのリターンで生活することです（私は40代前半です）。\n\n私は非常に分析的で、以前は大規模なファンドを運用していました。","locale":"ja"},{"title":"3个基金部署的风向标和实际问题","the_new_excerpt":"你好!\n\n我最近获得了1000多万美元的意外之财。最终，我的计划是\n部署一个简单的3个基金策略（可能使用DCA），每年重新平衡一次，然后\n靠收益过活（我已经40岁出头了）。\n\n我的分析能力很强，以前曾管理过大量的资金。","locale":"zh"},{"title":"3個基金部署的風向標和實際問題","the_new_excerpt":"你好!\n\n我最近獲得了1000多萬美元的意外之財。最終，我的計劃是\n部署一個簡單的3個基金策略（可能使用DCA），每年重新平衡一次，然後\n靠收益過活（我已經40歲出頭了）。\n\n我的分析能力很強，以前曾管理過大量的資金。","locale":"zh-Hant"}]}},"next":{"id":"RedditPost-2d55c58a-422a-52f8-9837-4aed27224caa","excerpt":"","slug":"/reddit/r/wallstreetbets/comments/nzq0yx/wish_yolo_see_you_at_25/","title":"$WISH ✋🏾💎🤚🏾 YOLO see you at $25 💎✋🏾🦍🙏🏿💪🏿","__typename":"SocialMediaPost","date":"June 15, 2021","parent":{"localize":[{"title":"$WISH ✋🏾💎🤚🏾 YOLO see you at $25 💎✋🏾🦍🙏🏿💪🏿","the_new_excerpt":null,"locale":"ja"},{"title":"$WISH ✋🏾💎🤚🏾YOLO在25美元处见到你💎✋🏾🦍🙏🏿💪🏿","the_new_excerpt":null,"locale":"zh"},{"title":"$WISH ✋🏾💎🤚🏾YOLO在25美元處見到你💎✋🏾🦍🙏🏿💪🏿","the_new_excerpt":null,"locale":"zh-Hant"}]}}},"pageContext":{"basePath":"/","pageType":"detail","id":"RedditPost-e228c254-01f9-5803-ac8e-ba555f8e0130","previousId":"RedditPost-8b349480-b58c-5e00-9146-2f700fbd375c","nextId":"RedditPost-2d55c58a-422a-52f8-9837-4aed27224caa","maxWidth":1024,"siteMetadata":null,"locale":"en","hrefLang":"en-US","originalPath":"/reddit/r/investing/comments/nzv40f/tracking_the_value_of_3_reddit_scrapers_for_30/","dateFormat":"MM/DD/YYYY"}},"staticQueryHashes":["1239077767","2744905544","3280999885"]}